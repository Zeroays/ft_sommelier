{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.1 Exploring the green reds\n",
    "<br>\n",
    "\n",
    "## **a) Plotting a scatter plot matrix of all red wine data variables, excluding quality.**\n",
    "<br>\n",
    "\n",
    "**Function \"plot_scatter_matrix\" was called with good_threshold == 8, bad_threshold == 3.**\n",
    "<br>\n",
    "\n",
    "**Obviously, can change threshold values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"winequality-red.csv\", delimiter = ';')\n",
    "\n",
    "def plot_scatter_matrix(wine_data, good_threshold, bad_threshold, save_plot=False):\n",
    "    params = list(data)\n",
    "    param_amt = len(params) - 1\n",
    "\n",
    "    plt.rc('xtick', labelsize=2)\n",
    "    plt.rc('ytick', labelsize=2)\n",
    "    \n",
    "    fig, plot = plt.subplots(param_amt, param_amt, figsize=(30, 22))\n",
    "    for i in range(param_amt):\n",
    "        for j in range(param_amt):\n",
    "            if i == j:\n",
    "                plot[i, i].text(0.5, 0.5, params[i], fontsize=12, ha='center', va='center')\n",
    "            else:\n",
    "                colors = ['green' if qlty >= good_threshold else 'purple' for qlty in data['quality']]\n",
    "                size = [1.5 if qlty >= good_threshold else 1.5 if qlty <= bad_threshold else 0 for qlty in data['quality']]\n",
    "                plot[i, j].scatter(data[params[i]], data[params[j]], s=size, c=colors)\n",
    "\n",
    "    if save_plot:\n",
    "        plt.savefig('scatter_matrix.png')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_scatter_matrix(data, 8, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b) Analyzing chemical factor variations in data to determine optimal choices to start Machine Learning process**\n",
    "<br>\n",
    "\n",
    "**The Perceptron works well with linearly separable data.  In other words, you can draw a line that separates the green points from the purple, and the two are completely divided.**\n",
    "<br>\n",
    "\n",
    "**Based on the scatter matrix above, there is a clear division in the pH vs alcohol, and citric acid vs density graphs.  For now, we will focus on pH vs alcohol content.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.2 Learning to perceptron\n",
    "<br>\n",
    "\n",
    "## **a) Implementing a perceptron with the following traits/properties/functionalities:**\n",
    "- **Randomly initialized weights and bias**\n",
    "- **Implements the Rosenblatt perceptron learning rule**\n",
    "- **Uses the Heaviside Step Acitvation Function (discrete version)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To filter out the data, we will create a function called \"add_qlty_column\" to modify the Pandas DataFrame (DF) for our Red Wine.**\n",
    "<br>\n",
    "\n",
    "**The table has been printed out for reference.  Notice that the DF only contains the alcohol and pH numbers, and its associative quality rating.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_qlty_column(wine_data, good_threshold, bad_threshold):\n",
    "    new_data = data.assign(Good=[1 if qlty >= good_threshold else 0 if qlty <= bad_threshold else -1 for qlty in data['quality']])\n",
    "    \n",
    "    threshold_filter = (new_data['quality'] >= good_threshold) | (new_data['quality'] <= bad_threshold)\n",
    "    data_with_quality = new_data[threshold_filter]\n",
    "    return data_with_quality\n",
    "\n",
    "updated_data = add_qlty_column(data, 8, 3)\n",
    "print(updated_data[['alcohol', 'pH', 'quality', 'Good']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Perceptron has been created as a class, since we can define properties and methods as a single object.**\n",
    "<br>\n",
    "\n",
    "**a) The random module has been imported to support random initialization of weights and bias.**\n",
    "<br>\n",
    "\n",
    "**b) The \"rosenblatt_learning\" method performs Task A.  The Rosenblatt Learning Rule executes until the specified iteration value (or epoch) is reached.  For each epoch, we calculate the difference between our expected Quality and the weighted sum using the pH, alcohol variables, our weights, and bias.**\n",
    "<br>\n",
    "\n",
    "**c) The amount of errors (after passing our weighted sum to the Heaviside Step Activation Function) is tracked through each epoch.  If it is 0, our program exits out of our loop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Perceptron():\n",
    "    def __init__(self, data, learning_rate):\n",
    "        self.data = data\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def heaviside_step_activation(self, activation):\n",
    "        return 1 if activation >= 0 else 0\n",
    "\n",
    "    def predict(self, params):\n",
    "        weighted_sum = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            weighted_sum += self.weights[i] * params[i]\n",
    "        weighted_sum += self.bias\n",
    "        return self.heaviside_step_activation(weighted_sum)\n",
    "        \n",
    "    def rosenblatt_learning(self):\n",
    "        self.bias = random.random()\n",
    "        self.weights = [random.random() for params in range(len(list(self.data)))]\n",
    "        \n",
    "        for itr in range(15000):\n",
    "            errors = 0\n",
    "            for x, y_true in zip(self.data.values, self.data['Good']):\n",
    "                error = y_true - self.predict(x)\n",
    "                if error != 0:\n",
    "                    self.weights += error * x * learning_rate\n",
    "                    self.bias += error * learning_rate\n",
    "                    errors += 1\n",
    "            if errors == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Implement a function to train the Perceptron\n",
    "<br>\n",
    "\n",
    "**The function should take in the Red Wine Data as a parameter, and have the following:**\n",
    "<br>\n",
    "\n",
    "- **Specify the number of epochs**\n",
    "- **Train perceptron until errors == 0, if the epochs is set to 0**\n",
    "- **Specify the learning rate**\n",
    "- **Return a list of python tuples that represents the Perceptron's performance -->**\n",
    "<br>\n",
    "\n",
    "**\\[(current_epoch, num_errors_at_epoch_end, [array_of_weights], bias), . . . \\]**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **Altering our Perceptron declaration above, we end up with the following \"finalized\" version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function for Perceptron.  Loops forever\"\"\"\n",
    "def infinity():\n",
    "    index = 0\n",
    "    while 1:\n",
    "        yield index\n",
    "        index += 1\n",
    "\n",
    "class Perceptron():\n",
    "    def __init__(self, data, learning_rate, epochs):\n",
    "        self.data = data\n",
    "        \"\"\"Learning Rate is already specified from previous Perceptron class declaration\"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        \"\"\"Specified epochs as parameter for Perceptron class\"\"\"\n",
    "        self.epochs = epochs\n",
    "        \"\"\"Performance is initialized as empty list, to be populated by learning method\"\"\"\n",
    "        self.performance = []\n",
    "        \n",
    "    def heaviside_step_activation(self, activation):\n",
    "        return 1 if activation >= 0 else 0\n",
    "\n",
    "    def predict(self, params):\n",
    "        weighted_sum = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            weighted_sum += self.weights[i] * params[i]\n",
    "        weighted_sum += self.bias\n",
    "        return self.heaviside_step_activation(weighted_sum)\n",
    "        \n",
    "    def rosenblatt_learning(self, y_cmp):\n",
    "        \"\"\"Set a seed for the random module, to prevent 'lucky' weights and biases\"\"\"\n",
    "        random.seed(9000)\n",
    "        self.bias = random.random()\n",
    "        self.weights = [random.random() for params in range(len(list(self.data)))]\n",
    "        \n",
    "        \"\"\"Utilizes the 'infinity' function above if epochs == 0, else loop until provided epoch is reached\"\"\"\n",
    "        for itr in infinity() if self.epochs == 0 else range(self.epochs):\n",
    "            errors = 0\n",
    "            for x, y_true in zip(self.data.values, y_cmp):\n",
    "                error = y_true - self.predict(x)\n",
    "                if error != 0:\n",
    "                    \"\"\"Learning rate is specified\"\"\"\n",
    "                    self.weights += error * x * self.learning_rate\n",
    "                    self.bias += error * self.learning_rate\n",
    "                    errors += 1\n",
    "            \"\"\"Tuple for tracking performance\"\"\"\n",
    "            self.performance.append((itr, errors, list(self.weights), self.bias))\n",
    "            if errors == 0:\n",
    "                break\n",
    "        return self.performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training our Perceptron, with a learning rate = 0.9, and setting epoch = 0, using our updated_data variable from above...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_perceptron = Perceptron(updated_data[['pH', 'alcohol']], 0.9, 0)\n",
    "perceptron_training = red_wine_perceptron.rosenblatt_learning(updated_data['Good'])\n",
    "print(perceptron_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Plot - Classification Errors vs Epoch &&  pH vs alcohol\n",
    "<br>\n",
    "\n",
    "\n",
    "**Focusing on using wines with a score/quality >= 8 && quality <= 3, pH vs alcohol, create two plots**\n",
    "<br>\n",
    "\n",
    "**The number of errors for each epoch should be plotted.  The decision boundary for pH vs alcohol should also appear alongside the previous plot, with two highlighted regions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Returns the min, max for the x_axis, y_axis of our wine_data - in this case, alcohol and pH respectively\"\"\"\n",
    "\"\"\"Function 'x_y_bounds' takes the x_axis, and y_axis wine_data array of values\"\"\"\n",
    "\"\"\"Returns a tuple - see return line\"\"\"\n",
    "def x_y_bounds(x_axis, y_axis, wine_data):\n",
    "    x_data = [x_val for x_val in wine_data[x_axis]]\n",
    "    y_data = [y_val for y_val in wine_data[y_axis]]\n",
    "    x_min, x_max = min(x_data), max(x_data)\n",
    "    y_min, y_max = min(y_data), max(y_data)\n",
    "    return (([x_min, x_max], [y_min, y_max]))\n",
    "\n",
    "\"\"\"Function 'setup_plot' is a helper function to decrease repetitiveness of main function below\"\"\"\n",
    "\"\"\"Sets title, x_label, and y_label, returning this modified plot\"\"\"\n",
    "def setup_plot(plot, title, x_label, y_label):\n",
    "    plot.set_title(title)\n",
    "    plot.set_xlabel(x_label)\n",
    "    plot.set_ylabel(y_label)\n",
    "    return plot\n",
    "\n",
    "\"\"\"Function 'plot_performance' takes in tuple from Perceptron learning function\"\"\"\n",
    "\"\"\"wine_data parameter - contains x_axis, y_axis, and quality column\"\"\"\n",
    "\"\"\"good_thresh, bad_thresh parameter - represents data of interest from quality column\"\"\"\n",
    "\"\"\"epoch parameter - Default -1 value to plot until epoch specified in Perceptron model, else only until\n",
    "specified epoch\"\"\"\n",
    "def plot_performance(performance, wine_data, good_thresh, bad_thresh, epoch=-1, save_plot=False):\n",
    "    \n",
    "    \"\"\"Get performance data from a specific epoch\"\"\"\n",
    "    def extract(index):\n",
    "        return [itr[index] for itr in performance]\n",
    "\n",
    "    \n",
    "    \"\"\"Derived point slope equation for plotting decision boundary\"\"\"\n",
    "    def y_val_decision_boundary(x, weight1, weight2, bias):\n",
    "        return (-weight1 / weight2) * x + (-bias / weight2)\n",
    "\n",
    "    \n",
    "    \"\"\"Declare variables within this function to represent our collected data\"\"\"\n",
    "    \"\"\"Also include ones for plot title, x and y axis labels\"\"\"\n",
    "    x_axis, y_axis, compare = 'alcohol', 'pH', 'quality'\n",
    "    epo_vs_error_title = 'Error as a function of epoch'\n",
    "    e_vs_e_x_title, e_vs_e_y_title = 'epoch', 'classification errors'\n",
    "    decision_boundary_title = 'Decision boundary on epoch'\n",
    "    epochs, errors, weights, bias = extract(0), extract(1), extract(2), extract(3)\n",
    "    epoch_choice = epoch if (epoch > 0 and epoch < len(performance)) else len(performance)\n",
    "\n",
    "    \n",
    "    \"\"\"Setup first plot - Classification Error vs Epoch\"\"\"\n",
    "    fig, plot = plt.subplots(1, 2, figsize=(25, 8))\n",
    "    plt.rc('xtick', labelsize=10)\n",
    "    plt.rc('ytick', labelsize=10)\n",
    "    epoch_vs_error = setup_plot(plot[0], epo_vs_error_title, e_vs_e_x_title, e_vs_e_y_title)\n",
    "    x_param_vs_y_param = setup_plot(plot[1], decision_boundary_title + \" : \" + str(epoch_choice), x_axis, y_axis)\n",
    "    \n",
    "    \n",
    "    \"\"\"Set x_axis and y_axis limits dynamically by finding their max values, and multiplying by percentage\"\"\"\n",
    "    epoch_buffer, errors_buffer = max(epochs) * 0.075, max(errors) * 0.075\n",
    "    plot[0].set(xlim=(min(epochs) - epoch_buffer, max(epochs) + epoch_buffer), ylim=(min(errors) - errors_buffer, max(errors) + errors_buffer))\n",
    "    plot[0].plot(epochs[:epoch_choice], errors[:epoch_choice], 'b--')\n",
    "\n",
    "    \n",
    "    \"\"\"Create variables to keep track of weights, and bias\"\"\"\n",
    "    b = bias[epoch_choice - 1]\n",
    "    weight1 = weights[epoch_choice - 1][0]\n",
    "    weight2 = weights[epoch_choice - 1][1]\n",
    "\n",
    "    \n",
    "    \"\"\"Separate bad wine and good wine into their own datasets\"\"\"\n",
    "    bad_wine = (wine_data[wine_data[compare] <= bad_thresh])[[x_axis, y_axis]]\n",
    "    good_wine = (wine_data[wine_data[compare] >= good_thresh])[[x_axis, y_axis]]\n",
    "    \n",
    "    \n",
    "    \"\"\"Set the x_axis, y_axis boundaries\"\"\"\n",
    "    \"\"\"Calls 'x_y_bounds' function from above to determine those limits\"\"\"\n",
    "    axis_bounds = x_y_bounds(x_axis, y_axis, wine_data)\n",
    "    x_decision_boundary = [i for i in range(-20, 20)]\n",
    "    y_decision_boundary = [y_val_decision_boundary(i, weight2, weight1, b) for i in range(-20, 20)]\n",
    "    \n",
    "    \n",
    "    \"\"\"Add additional buffers - extend limit on x_axis, y_axis\"\"\"\n",
    "    axis_buffer = 0.05 * min(axis_bounds[0][1], axis_bounds[1][1])\n",
    "    plot[1].set(xlim=(axis_bounds[0][0] - axis_buffer, axis_bounds[0][1] + axis_buffer), ylim=(axis_bounds[1][0] - axis_buffer, axis_bounds[1][1] + axis_buffer))\n",
    "    decision_boundary = plot[1].plot(x_decision_boundary, y_decision_boundary, 'b--')\n",
    "    \n",
    "    \n",
    "    \"\"\"Plot the bad and good wine with two separate calls to scatter\"\"\"\n",
    "    bad_wine_plot = plot[1].scatter(bad_wine[x_axis], bad_wine[y_axis], s=20, c='purple')\n",
    "    good_wine_plot = plot[1].scatter(good_wine[x_axis], good_wine[y_axis], s=20, c='green')\n",
    "    \n",
    "    \n",
    "    \"\"\"Use fill_between method to color two regions based on decision boundary\"\"\"\n",
    "    plot[1].fill_between(x_decision_boundary, axis_bounds[1][0] - axis_buffer, y_decision_boundary, facecolor='green', alpha=0.4)\n",
    "    plot[1].fill_between(x_decision_boundary, axis_bounds[1][1] + axis_buffer, y_decision_boundary, facecolor='pink', alpha=0.4)\n",
    "\n",
    "    \n",
    "    \"\"\"Create legend on right of second plot\"\"\"\n",
    "    plot[1].legend(['decision boundary' , 'bad wines (<=' + str(bad_thresh) + ' score)', 'good wines (>=' + str(good_thresh) + ' score)'], loc='upper left', bbox_to_anchor=(1,1), prop={'size':12})\n",
    "    \n",
    "    \n",
    "    \"\"\"Choice to save plot, if last parameter of plot_performance function is == True\"\"\"\n",
    "    if save_plot == True:\n",
    "        plt.savefig(\"perceptron_plot_performance.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_performance(perceptron_training, updated_data, 8, 3, 15000, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Feature Scaling - Modifications to Data for Faster Convergence\n",
    "<br>\n",
    "\n",
    "**Our data takes around 13,000 epochs to converge, even with a learning rate of 0.9 (max 1.0).**\n",
    "<br>\n",
    "\n",
    "**To reach our decision boundary faster, we can normalize our data to lie within a certain range**\n",
    "<br>\n",
    "\n",
    "**There are multiple different statistical methods to achieve this, such as standardization**\n",
    "<br>\n",
    "\n",
    "**For our data, we will use mean normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(data):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def mean_normalization(num, data, average):\n",
    "    return (num - average) / (max(data.values) - min(data.values))\n",
    "\n",
    "def with_feature_scaling(updated_data):\n",
    "    x_axis, y_axis = 'alcohol', 'pH'\n",
    "\n",
    "    graph_data = updated_data[[x_axis, y_axis, 'quality', 'Good']]\n",
    "\n",
    "    x_axis_avg = average(updated_data[x_axis].values)\n",
    "    y_axis_avg = average(updated_data[y_axis].values)\n",
    "    \n",
    "    x_norm = [mean_normalization(x, graph_data[x_axis], x_axis_avg) for x in graph_data[x_axis]]\n",
    "    graph_data = graph_data.assign(alcohol = x_norm)\n",
    "    \n",
    "    y_norm = [mean_normalization(y, graph_data[y_axis], y_axis_avg) for y in graph_data[y_axis]]\n",
    "    graph_data = graph_data.assign(pH = y_norm)\n",
    "\n",
    "    return graph_data\n",
    "\n",
    "normalized_data = with_feature_scaling(updated_data)\n",
    "print(normalized_data[['alcohol', 'pH', 'quality', 'Good']])\n",
    "\n",
    "red_wine_perceptron = Perceptron(normalized_data[['pH', 'alcohol']], 0.9, 0)\n",
    "perceptron_training = red_wine_perceptron.rosenblatt_learning(normalized_data['Good'])\n",
    "plot_performance(perceptron_training, normalized_data, 8, 3, 15000, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean normalized data allows the Perceptron to converge to 0 errors after approximately 50 epochs.**\n",
    "<br>\n",
    "\n",
    "**To keep our models consistent, the Perceptron is trained with a learning rate of 0.9.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.3 My fair ADALINE\n",
    "\n",
    "## a) Training our Perceptron with a larger range of Quality\n",
    "\n",
    "**A single perceptron can converge on a decision boundary, if our data is linearly separable.**\n",
    "<br>\n",
    "\n",
    "**By setting our quality threshold to cover a wider range of data, specifically wines with a score of 4, and with a score of 7 and higher, the perceptron cannot correctly train.**\n",
    "<br>\n",
    "\n",
    "**Our data points for these values overlap, making a separable linear boundary not possible.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_data = add_qlty_column(data, 7, 4)\n",
    "\n",
    "red_wine_perceptron = Perceptron(updated_data[['pH', 'alcohol']], 0.9, 0)\n",
    "#perceptron_training = red_wine_perceptron.rosenblatt_learning(updated_data['Good'])\n",
    "# plot_performance(perceptron_training, updated_data, 7, 4, 4, True)\n",
    "print(\"Hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
